**creating co-operatively run language models**

Many popular language models today are created by large, for-profit technology companies and serve the goals of these corporations. What would a language model look like if it was created by writers and to serve their creative community? Can we envision a co-operative language model that challenges existing notions of how technology is created and who it can serve?


## METAPHORS FOR MODEL GOVERNANCE

How would we govern a language model run for and by creative writers? We have collected over one hundred “metaphors for models” – projects, activities, collectives, locations that may make good metaphors for how to create and run a language model. For instance, what if a language model was like a community vegetable garden? Or a seed bank? Or the bathroom in a dive bar?

Below are some metaphors we have investigated deeply:

### Community Garden

Community gardens are small plots of land where local community members can be allotted a part of the plot to grow plants. This is often in urban areas where people may not have a backyard or may not have enough light in their yard or porch to grow what they would like. Community gardens tend to be free, but may have long wait times to get an allocation if they are popular. It’s run by volunteers who likely have their own allocation. Sometimes these gardens are fenced off to prevent animals from entering, but often they are not locked; anyone can come in and look around and there is no need to get a key or anything similar. 

What if a language model was like a community garden?

**Who are the data contributors?** The data is probably the garden contents: dirt, seeds, plants, flowers, vegetables, etc. While people bring their own seeds, the garden probably provides the dirt and maybe water. For a language model, this suggests that the members bring data to fine-tune the model on, but get to “own” model outputs (akin to the vegetables they grew). Probably members fine-tune their own version of the model, similar to how each garden member has their own allotment for growing. Since the garden provides the dirt, a “community garden” language model is probably fine-tuned on a shared existing model and the community independently hosts the shared model and the fine-tune versions (in the same way land is provided).

**Who are the model users?** The users are the same people who provide the data. Users would be co-located in some way, akin to a community garden being open to those living within a certain physical distance of the garden. Since everyone gets their own allotment in a shared space, maybe everyone’s model is accessible to others, but it’s considered rude to “take” from another person’s model. (Just like you wouldn’t pick your neighbors tomatoes.) Instead, you just get to look on.

**Who are the model stewards?** Community members volunteer to steward the garden. This means they manage the digital infrastructure, invite new members when old members leave, and make sure the community stays “tidy”. This could involve making sure that fine-tuning models is easy for new-comers, making sure that fine-tuned models are accessible, and updating shared base models when appropriate.

**What else does this metaphor suggest?** In this metaphor, it’s worth considering where the “land” comes from, which for a language model probably represents compute resources: model hosting and GPUs for training. In a community garden, it comes from the local municipality or council, which decides to take a lot of land that was otherwise not used or used for something else and makes it available to the community. This may mean that a “community garden” language model gets donated compute resources from some sort of community organization. This could be a university, a non-profit, maybe an independent art school, or even a local government that has compute resources.


## WORKSHOPS ON METAPHORS FOR MODELS 

Starting in February 2025, we ran a series of workshops to envision what a community-run creative language model could look like. These workshops seeded the analysis of “metaphors for models”. Below we summarize the workshops as a whole, and provide our materials for those interested in running their own. If you would like us to run a workshop with your community, please reach out ____.

[summary of workshops]

[links to materials: slides, run of show, template miro board]

## HISTORY OF THE PROJECT

This project arose from a research study we conducted on how creative writers reason about the use of their writing as training data for large language models.  Check out the published paper here.

Large language models (LLMs) present significant ethical concerns across a number of dimensions—from resource overuse to labor exploitation to intellectual theft. At the same time, LLMs have also demonstrated potential as artistic, pedagogical, and humanistic tools. Yet, as our previous study revealed, the problems with available LLMs make many people unwilling to use them, even if such models are humanistically interesting. 

There are ongoing efforts to reign in corporate LLMs, such as lawsuits to prevent the unconsensual use of writing as training data, and … There are also efforts to document and create more ethically-minded LLMs, such as the European Open Source AI Index to track how open LLMs truly are and OLMo, a state-of-the-art, truly open language model with inspectable training data. These are important efforts, but can remain distant for specific communities that may want to engage with this technology directly and on their own terms.

Our aim is to shepherd writer-led and contributed language models, where “creative writing as training data” is well-documented, full consent is provided by all contributing writers, and use cases are recorded and shared with community members. The training datasets and models will be guided by a community board. Such models would provide an ethical LLM options and be designed to prioritize community values like diversity and creativity.

## HOW YOU CAN CONTRIBUTE

- Anyone can submit an analysis of a metaphor for governance. Please use this form to submit a metaphor.
- Run a workshop! You are welcome to use our materials, or we are happy to help run a workshop for your community. If you run a workshop on your own, we would love to hear how it went! Please email _____.
- Interested in developing the technical backbones for training community language models? We are investigating different base models, fine-tuning paradigms, and how much data is needed to train a small model from scratch. Please email _____.
- We are piloting a small community language of just 10-20 writers; if you would like to participate, please email _____.
- Part of this project takes the form of Human-Computer Interaction research; if you are a researcher interested in collaborating on projects about data ethics and AI governance, please email ______.

## THE TEAM

Katy Gero—Katy is a post-doctoral fellow at Harvard University, soon to be a faculty in Computer Science at the University of Sydney. She's interested in figuring out how to challenge existing capitalist (and arguably colonial) language models with pro-social community ones.

Carly Schnitzler—Carly teaches writing at Johns Hopkins University and is the founder of If, Then: Technology and Poetics. Her teaching and research center digital rhetoric, creative computation, and the public humanities.

Meera Desai—Meera is a PhD student at University of Michigan where she studies responsible practices for developing and using language models for knowledge production. She’s interested in community-centered approaches to collecting and stewarding training data for language models.

Alicia Guo—Alicia is a PhD student at the University of Washington where she works on creativity support tools and investigating the processes behind creative uses of AI.

Carmel Schare—Carmel is a PhD student in Computer Science at MIT. His background includes research in digital humanities and programming languages. He is interested in the advantages and limitations of computers as tools that facilitate human creativity and collaboration.

Stephanie Young—Stephanie teaches writing on the Mills College campus at Northeastern University, where she serves as the NULab for Digital Humanities and Social Sciences Oakland coordinator. She's a poet, editor, and scholar whose writing often works between genres and combines digital tools with archival research.

